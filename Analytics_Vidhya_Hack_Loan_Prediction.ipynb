{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c29749",
   "metadata": {},
   "source": [
    "## Importing the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44bd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "##### Importing Packages for Data Imputation ------------------\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "##### Importing Packages for Model Validation -----------\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "##### Importing various classifiers ---------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9d31e",
   "metadata": {},
   "source": [
    "## Defining the functions to get the data and append the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c6e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    data=pd.read_csv(path)\n",
    "    return data\n",
    "def get_model():\n",
    "    model = []\n",
    "    model.append(LogisticRegression(max_iter=5000))\n",
    "    model.append(RidgeClassifier())\n",
    "    model.append(SGDClassifier())\n",
    "    model.append(PassiveAggressiveClassifier())\n",
    "    model.append(KNeighborsClassifier())\n",
    "    model.append(DecisionTreeClassifier())\n",
    "    model.append(ExtraTreeClassifier())\n",
    "    model.append(SVC())\n",
    "    model.append(GaussianNB())\n",
    "    model.append(AdaBoostClassifier())\n",
    "    model.append(BaggingClassifier())\n",
    "    model.append(RandomForestClassifier())\n",
    "    model.append(ExtraTreesClassifier())\n",
    "    model.append(GaussianProcessClassifier())\n",
    "    model.append(GradientBoostingClassifier())\n",
    "    model.append(LinearDiscriminantAnalysis())\n",
    "    model.append(QuadraticDiscriminantAnalysis())\n",
    "    model.append(xgboost.XGBClassifier())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f71408",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a00471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('Loan_Prediction_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bead370",
   "metadata": {},
   "source": [
    "## Filling the missing values using iterative imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74932bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroha\\AppData\\Local\\Temp\\ipykernel_25796\\2633724718.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y[i]=1\n",
      "C:\\Users\\aroha\\AppData\\Local\\Temp\\ipykernel_25796\\2633724718.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  else:Y[i]=0\n"
     ]
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "data.Gender.unique()\n",
    "#Categorical_Mapping_Key={'Gender':{'Female':0,'Male':1},'Married':{'Yes':1,'No':0},'Dependents':{'0':0,'1':1,'2':2,'3+':3},'Education':{'Graduate':1,'Not Graduate':0,'Self_Employed':{'Yes':1,'No':0},'Property_Area':{'Urban':1,'Rural':0,'Semi-Urban':0.5}}}\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Gender']=='Female':\n",
    "        data.loc[i,'Gender']=0\n",
    "    elif data.loc[i,'Gender']=='Male': \n",
    "        data.loc[i,'Gender']=1\n",
    "data.Gender.unique()\n",
    "\n",
    "data.Married.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Married']=='Yes':\n",
    "        data.loc[i,'Married']=1\n",
    "    elif data.loc[i,'Married']=='No': \n",
    "        data.loc[i,'Married']=0\n",
    "data.Married.unique()\n",
    "data.Dependents.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Dependents']=='0':\n",
    "        data.loc[i,'Dependents']=0\n",
    "    elif data.loc[i,'Dependents']=='1': \n",
    "        data.loc[i,'Dependents']=1\n",
    "    elif data.loc[i,'Dependents']=='2': \n",
    "        data.loc[i,'Dependents']=2\n",
    "    elif data.loc[i,'Dependents']=='3+': \n",
    "        data.loc[i,'Dependents']=3\n",
    "data.Dependents.unique()\n",
    "data.Education.unique()    \n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Education']=='Graduate':\n",
    "        data.loc[i,'Education']=1\n",
    "    else:\n",
    "        data.loc[i,'Education']=0\n",
    "data.Education.unique()\n",
    "data.Self_Employed.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Self_Employed']=='Yes':\n",
    "        data.loc[i,'Self_Employed']=1\n",
    "    elif data.loc[i,'Self_Employed']=='No': \n",
    "        data.loc[i,'Self_Employed']=0\n",
    "data.Self_Employed.unique()\n",
    "data.Credit_History.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Self_Employed']=='1.':\n",
    "        data.loc[i,'Self_Employed']=1\n",
    "    elif data.loc[i,'Self_Employed']=='0.': \n",
    "        data.loc[i,'Self_Employed']=0\n",
    "data.Credit_History.unique()\n",
    "data.Property_Area.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Property_Area']=='Urban':\n",
    "        data.loc[i,'Property_Area']=1\n",
    "    elif data.loc[i,'Property_Area']=='Rural':\n",
    "        data.loc[i,'Property_Area']=0\n",
    "    else:\n",
    "        data.loc[i,'Property_Area']=0.5\n",
    "data.Property_Area.unique()\n",
    "data.Loan_Status.unique()\n",
    "unique_values={'Loan_ID':data.Loan_ID.unique(),'Gender':data.Gender.unique(),'Married':data.Married.unique(),'Dependents':data.Dependents.unique(),'Education':data.Education.unique(),'Self_Employed':data.Self_Employed.unique(),'ApplicantIncome':data.ApplicantIncome.unique(),'CoapplicantIncome':data.CoapplicantIncome.unique(),'LoanAmount':data.LoanAmount.unique(),'Loan_Amount_Term':data.Loan_Amount_Term.unique(),'Credit_History':data.Credit_History.unique(),'Property_Area':data.Property_Area.unique(),'Loan_Status':data.Loan_Status.unique()}        \n",
    "unique_values\n",
    "na_columns=[i for i in data.columns if data[i].isnull().mean()>0]\n",
    "na_columns\n",
    "data[na_columns].isnull().mean()\n",
    "Y=data.loc[:,'Loan_Status']\n",
    "Y\n",
    "X=data.drop(['Loan_ID'],axis=1)\n",
    "X=X.drop(['Loan_Status'],axis=1)\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "imputed=imputer.fit_transform(X)\n",
    "data_imputed=pd.DataFrame(imputed,columns=X.columns)\n",
    "X = data_imputed\n",
    "for i in range(len(Y)):\n",
    "    if Y[i]=='Y':\n",
    "        Y[i]=1\n",
    "    else:Y[i]=0\n",
    "Y = Y.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a47519",
   "metadata": {},
   "source": [
    "## Getting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edaedc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2c63b",
   "metadata": {},
   "source": [
    "## Training all the models using 80 percent of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a4ebd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#precision_dict = {}\n",
    "trained_models = []\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    error_array = []\n",
    "    i = 0\n",
    "    model_1 = []\n",
    "    for j in range(20):\n",
    "        #X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "        model.fit(X,Y)\n",
    "        model_1.append(model)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         error_array.append(round(precision_score(Y_test,y_pred),2))\n",
    "#         if error_array[j]>i:\n",
    "#             i=j\n",
    "    trained_models.append(model_1[i])\n",
    "#     sum = 0\n",
    "#     for i in range(len(error_array)):\n",
    "#         sum = sum+error_array[i]\n",
    "#     sum = sum/(len(error_array))\n",
    "#     precision_dict[type(model).__name__] = sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f24a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(max_iter=5000),\n",
       " RidgeClassifier(),\n",
       " SGDClassifier(),\n",
       " PassiveAggressiveClassifier(),\n",
       " KNeighborsClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " ExtraTreeClassifier(),\n",
       " SVC(),\n",
       " GaussianNB(),\n",
       " AdaBoostClassifier(),\n",
       " BaggingClassifier(),\n",
       " RandomForestClassifier(),\n",
       " ExtraTreesClassifier(),\n",
       " GaussianProcessClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " LinearDiscriminantAnalysis(),\n",
       " QuadraticDiscriminantAnalysis(),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "               max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "               missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "               n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, ...)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e008394",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('Loan_Prediction_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b304885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>LP002971</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4009</td>\n",
       "      <td>1777</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>LP002975</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>LP002980</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3250</td>\n",
       "      <td>1993</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>LP002986</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>LP002989</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001015   Male     Yes          0      Graduate            No   \n",
       "1    LP001022   Male     Yes          1      Graduate            No   \n",
       "2    LP001031   Male     Yes          2      Graduate            No   \n",
       "3    LP001035   Male     Yes          2      Graduate            No   \n",
       "4    LP001051   Male      No          0  Not Graduate            No   \n",
       "..        ...    ...     ...        ...           ...           ...   \n",
       "362  LP002971   Male     Yes         3+  Not Graduate           Yes   \n",
       "363  LP002975   Male     Yes          0      Graduate            No   \n",
       "364  LP002980   Male      No          0      Graduate            No   \n",
       "365  LP002986   Male     Yes          0      Graduate            No   \n",
       "366  LP002989   Male      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5720                  0       110.0             360.0   \n",
       "1               3076               1500       126.0             360.0   \n",
       "2               5000               1800       208.0             360.0   \n",
       "3               2340               2546       100.0             360.0   \n",
       "4               3276                  0        78.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "362             4009               1777       113.0             360.0   \n",
       "363             4158                709       115.0             360.0   \n",
       "364             3250               1993       126.0             360.0   \n",
       "365             5000               2393       158.0             360.0   \n",
       "366             9200                  0        98.0             180.0   \n",
       "\n",
       "     Credit_History Property_Area  \n",
       "0               1.0         Urban  \n",
       "1               1.0         Urban  \n",
       "2               1.0         Urban  \n",
       "3               NaN         Urban  \n",
       "4               1.0         Urban  \n",
       "..              ...           ...  \n",
       "362             1.0         Urban  \n",
       "363             1.0         Urban  \n",
       "364             NaN     Semiurban  \n",
       "365             1.0         Rural  \n",
       "366             1.0         Rural  \n",
       "\n",
       "[367 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7c1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n",
    "data.Gender.unique()\n",
    "#Categorical_Mapping_Key={'Gender':{'Female':0,'Male':1},'Married':{'Yes':1,'No':0},'Dependents':{'0':0,'1':1,'2':2,'3+':3},'Education':{'Graduate':1,'Not Graduate':0,'Self_Employed':{'Yes':1,'No':0},'Property_Area':{'Urban':1,'Rural':0,'Semi-Urban':0.5}}}\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Gender']=='Female':\n",
    "        data.loc[i,'Gender']=0\n",
    "    elif data.loc[i,'Gender']=='Male': \n",
    "        data.loc[i,'Gender']=1\n",
    "data.Gender.unique()\n",
    "\n",
    "data.Married.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Married']=='Yes':\n",
    "        data.loc[i,'Married']=1\n",
    "    elif data.loc[i,'Married']=='No': \n",
    "        data.loc[i,'Married']=0\n",
    "data.Married.unique()\n",
    "data.Dependents.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Dependents']=='0':\n",
    "        data.loc[i,'Dependents']=0\n",
    "    elif data.loc[i,'Dependents']=='1': \n",
    "        data.loc[i,'Dependents']=1\n",
    "    elif data.loc[i,'Dependents']=='2': \n",
    "        data.loc[i,'Dependents']=2\n",
    "    elif data.loc[i,'Dependents']=='3+': \n",
    "        data.loc[i,'Dependents']=3\n",
    "data.Dependents.unique()\n",
    "data.Education.unique()    \n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Education']=='Graduate':\n",
    "        data.loc[i,'Education']=1\n",
    "    else:\n",
    "        data.loc[i,'Education']=0\n",
    "data.Education.unique()\n",
    "data.Self_Employed.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Self_Employed']=='Yes':\n",
    "        data.loc[i,'Self_Employed']=1\n",
    "    elif data.loc[i,'Self_Employed']=='No': \n",
    "        data.loc[i,'Self_Employed']=0\n",
    "data.Self_Employed.unique()\n",
    "data.Credit_History.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Self_Employed']=='1.':\n",
    "        data.loc[i,'Self_Employed']=1\n",
    "    elif data.loc[i,'Self_Employed']=='0.': \n",
    "        data.loc[i,'Self_Employed']=0\n",
    "data.Credit_History.unique()\n",
    "data.Property_Area.unique()\n",
    "for i in range(data.shape[0]):\n",
    "    if data.loc[i,'Property_Area']=='Urban':\n",
    "        data.loc[i,'Property_Area']=1\n",
    "    elif data.loc[i,'Property_Area']=='Rural':\n",
    "        data.loc[i,'Property_Area']=0\n",
    "    else:\n",
    "        data.loc[i,'Property_Area']=0.5\n",
    "data.Property_Area.unique()\n",
    "na_columns=[i for i in data.columns if data[i].isnull().mean()>0]\n",
    "na_columns\n",
    "data[na_columns].isnull().mean()\n",
    "Loan_ID = data[['Loan_ID']]\n",
    "X=data.drop(['Loan_ID'],axis=1)\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "imputed=imputer.fit_transform(X)\n",
    "data_imputed=pd.DataFrame(imputed,columns=X.columns)\n",
    "X = data_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb0c3424",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Predictions_1 = trained_models[-1].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75f3b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Status = []\n",
    "for i in range(len(Loan_Predictions_1)):\n",
    "    if Loan_Predictions_1[i]==1:\n",
    "        Loan_Status.append('Y')\n",
    "    else:Loan_Status.append(\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da0460d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Status = pd.DataFrame(Loan_Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d280a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat([Loan_ID,Loan_Status],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c75194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('C:/Users/aroha/OneDrive/Documents/MTech Materials/ML Data\\Analytics Vidya Hackathon/Loan_Prediction/predictions_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
